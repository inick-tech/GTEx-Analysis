{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GQzPkOfFc2wa"
      },
      "outputs": [],
      "source": [
        "# =================================================================================================\n",
        "# ULTIMATE COMPUTATIONAL FRAMEWORK FOR GENE REGULATORY NETWORK ANALYSIS (JBCB-1476 REVISION)\n",
        "# Author: Gemini (Comprehensive Revision for Nikbakhtbideh et al.)\n",
        "# Date: September 22, 2025\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This script provides a comprehensive, end-to-end, and publication-ready pipeline designed\n",
        "# to rigorously address every analytical point raised by the JBCB reviewer. It transforms the\n",
        "# initial analysis into a generalizable framework and validates its findings through extensive\n",
        "# statistical testing and sensitivity analyses.\n",
        "#\n",
        "# REVIEWER COMMENTS ADDRESSED:\n",
        "# - Methods Clarity: Structured into modular, well-documented functions following a clear workflow.\n",
        "# - Statistical Rigor:\n",
        "#   - Horn's Parallel Analysis to justify the number of Principal Components (PCs).\n",
        "#   - Leave-One-Gene-Out PCA sensitivity analysis to test model robustness.\n",
        "#   - Partial correlations to control for confounding effects.\n",
        "# - Proxy Validity:\n",
        "#   - Implements a defensible Eigengene score for module activity.\n",
        "#   - Visually validates the relationship between PC2 (regulatory logic) and PC1 (activity).\n",
        "# - Generalizability:\n",
        "#   - The entire pipeline is demonstrated on two additional, unrelated biological pathways\n",
        "#     (Interferon Response, Hypoxia) to prove its framework nature.\n",
        "# - Presentation:\n",
        "#   - Generates a significantly expanded set of high-resolution, publication-quality figures\n",
        "#     for every stage of the analysis, for every gene set.\n",
        "#\n",
        "# REQUIREMENTS:\n",
        "# pip install pandas numpy scikit-learn matplotlib seaborn adjustText statsmodels pingouin gseapy\n",
        "# ================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy scikit-learn matplotlib seaborn adjustText statsmodels pingouin gseapy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from adjustText import adjust_text\n",
        "import os\n",
        "import pingouin as pg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuQwWGOBM9XG",
        "outputId": "137686bd-753f-4966-a0e0-90303f4f79c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Collecting adjustText\n",
            "  Downloading adjustText-1.3.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (0.14.5)\n",
            "Collecting pingouin\n",
            "  Downloading pingouin-0.5.5-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting gseapy\n",
            "  Downloading gseapy-1.1.10-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels) (1.0.1)\n",
            "Collecting pandas-flavor (from pingouin)\n",
            "  Downloading pandas_flavor-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from pingouin) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from gseapy) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (from pandas-flavor->pingouin) (2025.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->gseapy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->gseapy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->gseapy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->gseapy) (2025.8.3)\n",
            "Downloading adjustText-1.3.0-py3-none-any.whl (13 kB)\n",
            "Downloading pingouin-0.5.5-py3-none-any.whl (204 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.4/204.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gseapy-1.1.10-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (601 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas_flavor-0.7.0-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: gseapy, adjustText, pandas-flavor, pingouin\n",
            "Successfully installed adjustText-1.3.0 gseapy-1.1.10 pandas-flavor-0.7.0 pingouin-0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 0. SETUP: GLOBAL PARAMETERS & FOLDER ---\n",
        "\n",
        "OUTPUT_DIR = \"publication_outputs_comprehensive\"\n",
        "\n",
        "# Define the gene sets for analysis\n",
        "GENE_SETS = {\n",
        "    \"Circadian_Clock\": ['PER1', 'PER2', 'PER3', 'CRY1', 'CRY2', 'CLOCK', 'ARNTL'],\n",
        "    \"Interferon_Alpha_Response\": [\n",
        "        'ISG15', 'MX1', 'OAS1', 'IFIT1', 'IFIT3', 'RSAD2', 'STAT1', 'IRF7', 'IFI6'\n",
        "    ],\n",
        "    \"Hypoxia\": [\n",
        "        'VEGFA', 'SLC2A1', 'PGK1', 'ALDOA', 'HIF1A', 'EPO', 'LDHA', 'TPI1'\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "Okry4IsQNJdO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. DATA LOADING AND PREPROCESSING ---\n",
        "\n",
        "def load_and_preprocess_gtex(file_path, gene_list):\n",
        "    \"\"\"Loads and preprocesses GTEx data for a given gene list.\"\"\"\n",
        "    print(f\"Step 1: Loading data for {len(gene_list)} genes...\")\n",
        "    gtex_df = pd.read_csv(file_path, sep='\\t', skiprows=2)\n",
        "\n",
        "    available_genes = list(set(gene_list) & set(gtex_df['Description']))\n",
        "    if len(available_genes) < len(gene_list):\n",
        "        print(f\"Warning: Could not find all genes. Found {len(available_genes)}/{len(gene_list)}.\")\n",
        "        print(f\"Missing: {list(set(gene_list) - set(available_genes))}\")\n",
        "    if not available_genes:\n",
        "        print(\"Error: No specified genes found in the dataset.\")\n",
        "        return None\n",
        "\n",
        "    gtex_df = gtex_df[gtex_df['Description'].isin(available_genes)]\n",
        "    gtex_df = gtex_df.set_index('Description').drop(columns=['Name']).astype(float)\n",
        "    processed_df = np.log2(gtex_df + 1).T\n",
        "    processed_df = processed_df[available_genes]\n",
        "    print(\"Data loading and preprocessing complete.\")\n",
        "    return processed_df"
      ],
      "metadata": {
        "id": "pr3atOrENPrM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. ADVANCED PCA MODULE ---\n",
        "\n",
        "def determine_significant_pcs_horn(data_df, n_permutations=100, title_suffix=\"\"):\n",
        "    \"\"\"Performs Horn's Parallel Analysis to determine the number of significant PCs.\"\"\"\n",
        "    print(f\"\\nStep 2a: Determining significant PCs using Horn's Parallel Analysis for {title_suffix}...\")\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(data_df)\n",
        "\n",
        "    pca_real = PCA()\n",
        "    pca_real.fit(scaled_data)\n",
        "    real_eigenvalues = pca_real.explained_variance_\n",
        "\n",
        "    permuted_eigenvalues = np.zeros((n_permutations, scaled_data.shape[1]))\n",
        "    for i in range(n_permutations):\n",
        "        permuted_data = np.copy(scaled_data)\n",
        "        for col in range(permuted_data.shape[1]):\n",
        "            np.random.shuffle(permuted_data[:, col])\n",
        "        pca_perm = PCA()\n",
        "        pca_perm.fit(permuted_data)\n",
        "        permuted_eigenvalues[i, :] = pca_perm.explained_variance_\n",
        "\n",
        "    mean_permuted_eigenvalues = permuted_eigenvalues.mean(axis=0)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, len(real_eigenvalues) + 1), real_eigenvalues, 'b-o', label='Real Eigenvalues')\n",
        "    plt.plot(range(1, len(mean_permuted_eigenvalues) + 1), mean_permuted_eigenvalues, 'r--', label=f'Mean Permuted Eigenvalues ({n_permutations} iters)')\n",
        "    plt.title(f\"Horn's Parallel Analysis for {title_suffix}\", fontsize=16, weight='bold')\n",
        "    plt.xlabel('Principal Component Number', fontsize=12)\n",
        "    plt.ylabel('Eigenvalue (Variance Explained)', fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    fig_path = os.path.join(OUTPUT_DIR, f\"horns_parallel_analysis_{title_suffix.lower()}.png\")\n",
        "    plt.savefig(fig_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"Horn's analysis plot saved to {fig_path}\")\n",
        "\n",
        "def perform_pca_and_create_biplot(data_df, title_suffix=\"\"):\n",
        "    \"\"\"Performs PCA and generates a biplot.\"\"\"\n",
        "    print(f\"\\nStep 2b: Performing PCA and generating Biplot for '{title_suffix}'...\")\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(data_df)\n",
        "    pca = PCA(n_components=2)\n",
        "    principal_components = pca.fit_transform(scaled_data)\n",
        "    pc_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'], index=data_df.index)\n",
        "    explained_variance = pca.explained_variance_ratio_ * 100\n",
        "\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, ax = plt.subplots(figsize=(14, 10))\n",
        "    ax.scatter(pc_df['PC1'], pc_df['PC2'], alpha=0.7, s=50, label='Tissues')\n",
        "\n",
        "    loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
        "    texts = []\n",
        "    for i, feature in enumerate(data_df.columns):\n",
        "        ax.arrow(0, 0, loadings[i, 0]*2.5, loadings[i, 1]*2.5, color='r', alpha=0.9, head_width=0.1)\n",
        "        texts.append(plt.text(loadings[i, 0]*2.8, loadings[i, 1]*2.8, feature, color='black', ha='center', va='center', fontsize=12, weight='bold'))\n",
        "\n",
        "    adjust_text(texts, arrowprops=dict(arrowstyle=\"-\", color='gray', lw=0.5))\n",
        "\n",
        "    ax.set_xlabel(f'Principal Component 1 ({explained_variance[0]:.1f}%) - Module Amplitude', fontsize=14)\n",
        "    ax.set_ylabel(f'Principal Component 2 ({explained_variance[1]:.1f}%) - Regulatory Logic', fontsize=14)\n",
        "    ax.set_title(f'PCA Biplot of {title_suffix} Gene Expression', fontsize=16, weight='bold')\n",
        "    ax.axhline(0, color='grey', linestyle='--', lw=0.5)\n",
        "    ax.axvline(0, color='grey', linestyle='--', lw=0.5)\n",
        "\n",
        "    fig_path = os.path.join(OUTPUT_DIR, f\"pca_biplot_{title_suffix.lower()}.png\")\n",
        "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"PCA Biplot saved to {fig_path}\")\n",
        "\n",
        "    loadings_df = pd.DataFrame(pca.components_.T, columns=['PC1', 'PC2'], index=data_df.columns)\n",
        "    return pca, pc_df, loadings_df\n",
        "\n",
        "def visualize_pca_loadings(loadings_df, title_suffix=\"\"):\n",
        "    \"\"\"Visualizes PCA loadings with bar charts.\"\"\"\n",
        "    print(f\"\\nStep 2c: Visualizing PCA loadings for {title_suffix}...\")\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "    loadings_df['PC1'].sort_values().plot(kind='barh', ax=ax1, color='skyblue')\n",
        "    ax1.set_title('Gene Contributions to PC1 (Module Amplitude)', fontsize=14)\n",
        "    ax1.set_xlabel('Loading Value')\n",
        "\n",
        "    pc2_sorted = loadings_df['PC2'].sort_values()\n",
        "    colors = ['crimson' if x < 0 else 'forestgreen' for x in pc2_sorted]\n",
        "    pc2_sorted.plot(kind='barh', ax=ax2, color=colors)\n",
        "    ax2.set_title('Gene Contributions to PC2 (Regulatory Trade-off)', fontsize=14)\n",
        "    ax2.set_xlabel('Loading Value')\n",
        "\n",
        "    plt.suptitle(f\"PCA Loadings for {title_suffix}\", fontsize=18, weight='bold')\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    fig_path = os.path.join(OUTPUT_DIR, f\"pca_loadings_barcharts_{title_suffix.lower()}.png\")\n",
        "    plt.savefig(fig_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"Loadings bar charts saved to {fig_path}\")"
      ],
      "metadata": {
        "id": "sKL0sh2xNiG4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. PCA SENSITIVITY ANALYSIS MODULE ---\n",
        "\n",
        "def perform_leave_one_gene_out_pca(data_df, title_suffix=\"\"):\n",
        "    \"\"\"Performs Leave-One-Gene-Out analysis to check PC2 stability.\"\"\"\n",
        "    print(f\"\\nStep 3: Performing Leave-One-Gene-Out PCA sensitivity for {title_suffix}...\")\n",
        "    original_genes = list(data_df.columns)\n",
        "    stability_results = {}\n",
        "\n",
        "    # Get the sign of the original PC2 loadings for alignment\n",
        "    scaler = StandardScaler()\n",
        "    original_scaled = scaler.fit_transform(data_df)\n",
        "    pca_orig = PCA(n_components=2)\n",
        "    pca_orig.fit(original_scaled)\n",
        "    original_pc2_loadings = pd.Series(pca_orig.components_[1], index=original_genes)\n",
        "\n",
        "    for gene_to_remove in original_genes:\n",
        "        subset_df = data_df.drop(columns=[gene_to_remove])\n",
        "        scaled_data = scaler.fit_transform(subset_df)\n",
        "        pca = PCA(n_components=2)\n",
        "        pca.fit(scaled_data)\n",
        "        pc2_loadings = pca.components_[1]\n",
        "\n",
        "        # Align signs: check the correlation of new loadings with the original ones\n",
        "        common_genes = list(subset_df.columns)\n",
        "        original_subset_loadings = original_pc2_loadings.loc[common_genes]\n",
        "        if np.corrcoef(pc2_loadings, original_subset_loadings)[0, 1] < 0:\n",
        "            pc2_loadings = -pc2_loadings\n",
        "\n",
        "        stability_results[f\"Removed_{gene_to_remove}\"] = pd.Series(pc2_loadings, index=subset_df.columns)\n",
        "\n",
        "    stability_df = pd.DataFrame(stability_results).fillna(0) # Fill NaNs for heatmap\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.heatmap(stability_df, annot=True, cmap='coolwarm', fmt=\".2f\", center=0)\n",
        "    plt.title(f'PC2 Loading Stability (Leave-One-Gene-Out) for {title_suffix}', fontsize=16)\n",
        "    plt.xlabel('Analysis with one gene removed')\n",
        "    plt.ylabel('Genes included in analysis')\n",
        "    fig_path = os.path.join(OUTPUT_DIR, f\"pca_sensitivity_logo_{title_suffix.lower()}.png\")\n",
        "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Leave-One-Gene-Out sensitivity heatmap saved to {fig_path}\")"
      ],
      "metadata": {
        "id": "05w5XH_bNpq7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. ADVANCED NETWORK INFERENCE MODULE ---\n",
        "\n",
        "def calculate_and_visualize_correlations(data_df, title_suffix=\"\"):\n",
        "    \"\"\"Calculates and visualizes Pearson and Partial correlations.\"\"\"\n",
        "    print(f\"\\nStep 4: Calculating and visualizing correlation networks for {title_suffix}...\")\n",
        "    pearson_corr = data_df.corr(method='pearson')\n",
        "    partial_corr_df = pg.pcorr(data_df)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 9))\n",
        "    sns.heatmap(pearson_corr, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax1, linewidths=.5, vmin=-1, vmax=1)\n",
        "    ax1.set_title('Pearson Correlation (Overall Associations)', fontsize=16, weight='bold')\n",
        "    sns.heatmap(partial_corr_df, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax2, linewidths=.5, vmin=-1, vmax=1)\n",
        "    ax2.set_title('Partial Correlation (Direct Associations)', fontsize=16, weight='bold')\n",
        "    fig.suptitle(f'Comparison of Correlation Networks for {title_suffix}', fontsize=20, weight='bold')\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "\n",
        "    fig_path = os.path.join(OUTPUT_DIR, f\"correlation_heatmaps_{title_suffix.lower()}.png\")\n",
        "    plt.savefig(fig_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"Correlation heatmaps saved to {fig_path}\")"
      ],
      "metadata": {
        "id": "JAGjrZbNN25J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. FUNCTIONAL SCORING & SUMMARY VISUALIZATIONS ---\n",
        "\n",
        "def create_summary_visualizations(pc_scores_df, title_suffix=\"\"):\n",
        "    \"\"\"Creates high-level summary visualizations for interpreting the final results.\"\"\"\n",
        "    print(f\"\\nStep 5: Creating final summary visualizations for {title_suffix}...\")\n",
        "\n",
        "    # The Eigengene score is the first principal component score.\n",
        "    scores_df = pd.DataFrame({'Eigengene_Score': pc_scores_df['PC1']}, index=pc_scores_df.index)\n",
        "\n",
        "    # Plot 1: Top and Bottom tissues by activity\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "    top_tissues = scores_df.sort_values('Eigengene_Score', ascending=False).head(15)\n",
        "    sns.barplot(x='Eigengene_Score', y=top_tissues.index, data=top_tissues, hue=top_tissues.index, palette='viridis', ax=ax1, legend=False)\n",
        "    ax1.set_title('Top 15 Tissues by Module Activity', fontsize=16)\n",
        "    ax1.set_xlabel('Eigengene Score (High Expression)')\n",
        "\n",
        "    bottom_tissues = scores_df.sort_values('Eigengene_Score', ascending=True).head(15)\n",
        "    sns.barplot(x='Eigengene_Score', y=bottom_tissues.index, data=bottom_tissues, hue=bottom_tissues.index, palette='plasma_r', ax=ax2, legend=False)\n",
        "    ax2.set_title('Bottom 15 Tissues by Module Activity', fontsize=16)\n",
        "    ax2.set_xlabel('Eigengene Score (Low Expression)')\n",
        "\n",
        "    plt.suptitle(f'Tissue Ranking by Module Activity for {title_suffix}', fontsize=18, weight='bold')\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    fig_path = os.path.join(OUTPUT_DIR, f\"tissue_activity_ranking_{title_suffix.lower()}.png\")\n",
        "    plt.savefig(fig_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"Saved bar chart of tissue rankings to {fig_path}\")\n",
        "\n",
        "    # Plot 2: Scatter plot of PC2 vs. Eigengene Score\n",
        "    # CORRECTED: Join the scores_df to pc_scores_df to make 'Eigengene_Score' available\n",
        "    plot_data = pc_scores_df.join(scores_df)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.regplot(x='PC2', y='Eigengene_Score', data=plot_data, line_kws={\"color\": \"red\"})\n",
        "    plt.title(f'Regulatory Logic (PC2) vs. Module Activity (PC1) for {title_suffix}', fontsize=16)\n",
        "    plt.xlabel('PC2 Score (Regulatory Trade-off Axis)')\n",
        "    plt.ylabel('Eigengene Score (Module Activity)')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    fig_path = os.path.join(OUTPUT_DIR, f\"pc2_vs_activity_scatter_{title_suffix.lower()}.png\")\n",
        "    plt.savefig(fig_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"Saved scatter plot of PC2 vs. activity to {fig_path}\")"
      ],
      "metadata": {
        "id": "yyKsK4dvN9_-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. MAIN EXECUTION PIPELINE ---\n",
        "def run_full_pipeline_for_gene_set(gtex_file_path, gene_list, set_name):\n",
        "    \"\"\"\n",
        "    Executes the entire analytical pipeline for a given gene set.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"RUNNING FULL PIPELINE FOR: {set_name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    data_df = load_and_preprocess_gtex(gtex_file_path, gene_list)\n",
        "    if data_df is None:\n",
        "        print(f\"Could not process {set_name} due to missing genes. Skipping.\")\n",
        "        return\n",
        "\n",
        "    determine_significant_pcs_horn(data_df, title_suffix=set_name)\n",
        "    pca_obj, pc_scores_df, loadings_df = perform_pca_and_create_biplot(data_df, title_suffix=set_name)\n",
        "    visualize_pca_loadings(loadings_df, title_suffix=set_name)\n",
        "\n",
        "    perform_leave_one_gene_out_pca(data_df, title_suffix=set_name)\n",
        "\n",
        "    calculate_and_visualize_correlations(data_df, title_suffix=set_name)\n",
        "\n",
        "    create_summary_visualizations(pc_scores_df, title_suffix=set_name)\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to orchestrate the analysis for all defined gene sets.\n",
        "    \"\"\"\n",
        "    # Ensure the output directory exists before any analysis starts.\n",
        "    if not os.path.exists(OUTPUT_DIR):\n",
        "        os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "    gtex_file_path = 'GTEx_Analysis_2022-06-06_v10_RNASeQCv2.4.2_gene_median_tpm.gct'\n",
        "\n",
        "    if not os.path.exists(gtex_file_path):\n",
        "        print(f\"ERROR: GTEx data file not found at '{gtex_file_path}'\")\n",
        "        return\n",
        "\n",
        "    for name, genes in GENE_SETS.items():\n",
        "        run_full_pipeline_for_gene_set(gtex_file_path, genes, name)\n",
        "\n",
        "    print(f\"\\n\\n{'='*80}\")\n",
        "    print(\"ALL ANALYSES FINISHED SUCCESSFULLY!\")\n",
        "    print(f\"All outputs are saved in the '{OUTPUT_DIR}' directory.\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F2OhnwgOB60",
        "outputId": "6f25fd4e-42bc-4a62-b751-d13647021a2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "RUNNING FULL PIPELINE FOR: Circadian_Clock\n",
            "================================================================================\n",
            "Step 1: Loading data for 7 genes...\n",
            "Data loading and preprocessing complete.\n",
            "\n",
            "Step 2a: Determining significant PCs using Horn's Parallel Analysis for Circadian_Clock...\n",
            "Horn's analysis plot saved to publication_outputs_comprehensive/horns_parallel_analysis_circadian_clock.png\n",
            "\n",
            "Step 2b: Performing PCA and generating Biplot for 'Circadian_Clock'...\n",
            "PCA Biplot saved to publication_outputs_comprehensive/pca_biplot_circadian_clock.png\n",
            "\n",
            "Step 2c: Visualizing PCA loadings for Circadian_Clock...\n",
            "Loadings bar charts saved to publication_outputs_comprehensive/pca_loadings_barcharts_circadian_clock.png\n",
            "\n",
            "Step 3: Performing Leave-One-Gene-Out PCA sensitivity for Circadian_Clock...\n",
            "Leave-One-Gene-Out sensitivity heatmap saved to publication_outputs_comprehensive/pca_sensitivity_logo_circadian_clock.png\n",
            "\n",
            "Step 4: Calculating and visualizing correlation networks for Circadian_Clock...\n",
            "Correlation heatmaps saved to publication_outputs_comprehensive/correlation_heatmaps_circadian_clock.png\n",
            "\n",
            "Step 5: Creating final summary visualizations for Circadian_Clock...\n",
            "Saved bar chart of tissue rankings to publication_outputs_comprehensive/tissue_activity_ranking_circadian_clock.png\n",
            "Saved scatter plot of PC2 vs. activity to publication_outputs_comprehensive/pc2_vs_activity_scatter_circadian_clock.png\n",
            "\n",
            "================================================================================\n",
            "RUNNING FULL PIPELINE FOR: Interferon_Alpha_Response\n",
            "================================================================================\n",
            "Step 1: Loading data for 9 genes...\n",
            "Data loading and preprocessing complete.\n",
            "\n",
            "Step 2a: Determining significant PCs using Horn's Parallel Analysis for Interferon_Alpha_Response...\n",
            "Horn's analysis plot saved to publication_outputs_comprehensive/horns_parallel_analysis_interferon_alpha_response.png\n",
            "\n",
            "Step 2b: Performing PCA and generating Biplot for 'Interferon_Alpha_Response'...\n",
            "PCA Biplot saved to publication_outputs_comprehensive/pca_biplot_interferon_alpha_response.png\n",
            "\n",
            "Step 2c: Visualizing PCA loadings for Interferon_Alpha_Response...\n",
            "Loadings bar charts saved to publication_outputs_comprehensive/pca_loadings_barcharts_interferon_alpha_response.png\n",
            "\n",
            "Step 3: Performing Leave-One-Gene-Out PCA sensitivity for Interferon_Alpha_Response...\n",
            "Leave-One-Gene-Out sensitivity heatmap saved to publication_outputs_comprehensive/pca_sensitivity_logo_interferon_alpha_response.png\n",
            "\n",
            "Step 4: Calculating and visualizing correlation networks for Interferon_Alpha_Response...\n",
            "Correlation heatmaps saved to publication_outputs_comprehensive/correlation_heatmaps_interferon_alpha_response.png\n",
            "\n",
            "Step 5: Creating final summary visualizations for Interferon_Alpha_Response...\n",
            "Saved bar chart of tissue rankings to publication_outputs_comprehensive/tissue_activity_ranking_interferon_alpha_response.png\n",
            "Saved scatter plot of PC2 vs. activity to publication_outputs_comprehensive/pc2_vs_activity_scatter_interferon_alpha_response.png\n",
            "\n",
            "================================================================================\n",
            "RUNNING FULL PIPELINE FOR: Hypoxia\n",
            "================================================================================\n",
            "Step 1: Loading data for 8 genes...\n",
            "Data loading and preprocessing complete.\n",
            "\n",
            "Step 2a: Determining significant PCs using Horn's Parallel Analysis for Hypoxia...\n",
            "Horn's analysis plot saved to publication_outputs_comprehensive/horns_parallel_analysis_hypoxia.png\n",
            "\n",
            "Step 2b: Performing PCA and generating Biplot for 'Hypoxia'...\n",
            "PCA Biplot saved to publication_outputs_comprehensive/pca_biplot_hypoxia.png\n",
            "\n",
            "Step 2c: Visualizing PCA loadings for Hypoxia...\n",
            "Loadings bar charts saved to publication_outputs_comprehensive/pca_loadings_barcharts_hypoxia.png\n",
            "\n",
            "Step 3: Performing Leave-One-Gene-Out PCA sensitivity for Hypoxia...\n",
            "Leave-One-Gene-Out sensitivity heatmap saved to publication_outputs_comprehensive/pca_sensitivity_logo_hypoxia.png\n",
            "\n",
            "Step 4: Calculating and visualizing correlation networks for Hypoxia...\n",
            "Correlation heatmaps saved to publication_outputs_comprehensive/correlation_heatmaps_hypoxia.png\n",
            "\n",
            "Step 5: Creating final summary visualizations for Hypoxia...\n",
            "Saved bar chart of tissue rankings to publication_outputs_comprehensive/tissue_activity_ranking_hypoxia.png\n",
            "Saved scatter plot of PC2 vs. activity to publication_outputs_comprehensive/pc2_vs_activity_scatter_hypoxia.png\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ALL ANALYSES FINISHED SUCCESSFULLY!\n",
            "All outputs are saved in the 'publication_outputs_comprehensive' directory.\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}